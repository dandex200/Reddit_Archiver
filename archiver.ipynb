{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ▄████████    ▄████████ ████████▄  ████████▄   ▄█      ███             ▄████████    ▄████████  ▄████████    ▄█    █▄     ▄█   ▄█    █▄     ▄████████    ▄████████\n",
    "#   ███    ███   ███    ███ ███   ▀███ ███   ▀███ ███  ▀█████████▄        ███    ███   ███    ███ ███    ███   ███    ███   ███  ███    ███   ███    ███   ███    ███\n",
    "#   ███    ███   ███    █▀  ███    ███ ███    ███ ███▌    ▀███▀▀██        ███    ███   ███    ███ ███    █▀    ███    ███   ███▌ ███    ███   ███    █▀    ███    ███\n",
    "#  ▄███▄▄▄▄██▀  ▄███▄▄▄     ███    ███ ███    ███ ███▌     ███   ▀        ███    ███  ▄███▄▄▄▄██▀ ███         ▄███▄▄▄▄███▄▄ ███▌ ███    ███  ▄███▄▄▄      ▄███▄▄▄▄██▀\n",
    "# ▀▀███▀▀▀▀▀   ▀▀███▀▀▀     ███    ███ ███    ███ ███▌     ███          ▀███████████ ▀▀███▀▀▀▀▀   ███        ▀▀███▀▀▀▀███▀  ███▌ ███    ███ ▀▀███▀▀▀     ▀▀███▀▀▀▀▀\n",
    "# ▀███████████   ███    █▄  ███    ███ ███    ███ ███      ███            ███    ███ ▀███████████ ███    █▄    ███    ███   ███  ███    ███   ███    █▄  ▀███████████\n",
    "#   ███    ███   ███    ███ ███   ▄███ ███   ▄███ ███      ███            ███    ███   ███    ███ ███    ███   ███    ███   ███  ███    ███   ███    ███   ███    ███\n",
    "#   ███    ███   ██████████ ████████▀  ████████▀  █▀      ▄████▀          ███    █▀    ███    ███ ████████▀    ███    █▀    █▀    ▀██████▀    ██████████   ███    ███\n",
    "#   ███    ███                                                                         ███    ███                                                          ███    ███"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Archiver - An easy way to archive and view your Reddit Account. \n",
    "\n",
    "Downloads your profile info and posts/comments from your input reddit account. Creates a presentable webpage of your arhcived profile that can be saved locally. \n",
    "\n",
    "* Allows user to input desired Reddit Username and output directory for archive file via command line\n",
    "* Downloads user data using BeautifulSoup.\n",
    "* Saves data to JSON file\n",
    "* Loads JSON File into HTML webpage and saves webpage to desired directory\n",
    "\n",
    "\n",
    "By [dandex200](https://github.com/dandex200/) on Github\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from tkinter import filedialog, Tk\n",
    "import datetime\n",
    "import youtube_dl\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing New Uniform GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"139945526675968<lambda>\"\n",
      "    while executing\n",
      "\"139945526675968<lambda>\"\n",
      "    (\"after\" script)\n",
      "invalid command name \"139945527075136<lambda>\"\n",
      "    while executing\n",
      "\"139945527075136<lambda>\"\n",
      "    (\"after\" script)\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "import tkinter.messagebox\n",
    "import customtkinter\n",
    "\n",
    "customtkinter.set_appearance_mode(\"System\")  # Modes: \"System\" (standard), \"Dark\", \"Light\"\n",
    "customtkinter.set_default_color_theme(\"blue\")  # Themes: \"blue\" (standard), \"green\", \"dark-blue\"\n",
    "\n",
    "\n",
    "class App(customtkinter.CTk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.title(\"CustomTkinter complex_example.py\")\n",
    "        self.geometry(f\"{1100}x{580}\")\n",
    "        self.grid_columnconfigure(0, weight=0)\n",
    "        self.grid_columnconfigure(1, weight=2)\n",
    "        self.grid_rowconfigure((0, 1, 2), weight=1)\n",
    "\n",
    "        #Sidebar Frame\n",
    "        self.sidebar_frame = customtkinter.CTkFrame(self, corner_radius=0)\n",
    "        self.sidebar_frame.grid(row=0, column=0, rowspan=3, sticky=\"nsew\")\n",
    "        self.sidebar_frame.grid_rowconfigure(4, weight=1)\n",
    "        self.title_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"Reddit Archiver\", font=customtkinter.CTkFont(size=20, weight=\"bold\"))\n",
    "        self.title_label.grid(row=0, column=0, padx=20, pady=(20, 10))\n",
    "        self.footer_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"by dandex200\")\n",
    "        self.footer_label.grid(row=5, column=0, padx=20, pady=(20, 10))\n",
    "\n",
    "        #Main Frame\n",
    "        self.main_frame = customtkinter.CTkFrame(self, corner_radius=0)\n",
    "        self.main_frame.grid(row=0, column=1, rowspan=3, sticky=\"nsew\")\n",
    "        self.username_label = customtkinter.CTkLabel(self.main_frame, text=\"Username:\")\n",
    "        self.username_label.grid(row=0, column=1, padx=20, pady=(20, 5), sticky=\"w\")\n",
    "        self.username_entry = customtkinter.CTkTextbox(self.main_frame, width=250, height=30)\n",
    "        self.username_entry.grid(row=1, column=1, padx=20, pady=(0, 20), sticky=\"w\")\n",
    "        self.output_label = customtkinter.CTkLabel(self.main_frame, text=\"Select Output Directory:\")\n",
    "        self.output_label.grid(row=2, column=1, padx=20, pady=(20, 5), sticky=\"w\")\n",
    "        self.output_entry = customtkinter.CTkTextbox(self.main_frame, width=250, height=30)\n",
    "        self.output_entry.grid(row=3, column=1, padx=20, pady=(0, 20), sticky=\"w\")\n",
    "\n",
    "        self.checkbox_slider_frame = customtkinter.CTkFrame(self.main_frame)\n",
    "        self.checkbox_slider_frame.grid(row=4, column=1, padx=(20, 20), pady=(20, 0), sticky=\"nsew\")\n",
    "        self.checkbox_1 = customtkinter.CTkCheckBox(master=self.checkbox_slider_frame)\n",
    "        self.checkbox_1.grid(row=1, column=0, pady=(20, 0), padx=20, sticky=\"n\")\n",
    "        self.checkbox_2 = customtkinter.CTkCheckBox(master=self.checkbox_slider_frame)\n",
    "        self.checkbox_2.grid(row=2, column=0, pady=(20, 0), padx=20, sticky=\"n\")\n",
    "        self.checkbox_3 = customtkinter.CTkCheckBox(master=self.checkbox_slider_frame)\n",
    "        self.checkbox_3.grid(row=3, column=0, pady=20, padx=20, sticky=\"n\")\n",
    "\n",
    "        self.start_button = customtkinter.CTkButton(self.main_frame, command=self.button_pressed, text=\"START\")\n",
    "        self.start_button.grid(row=5, column=2, padx=20, pady=10)\n",
    "\n",
    "        #Functions\n",
    "    def button_pressed(self):\n",
    "        print(\"button click\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = App()\n",
    "    app.mainloop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save archive file to: /home/dandex/programming/The_Reddit_Archiver/Reddit_Archiver/Temp_Files\n"
     ]
    }
   ],
   "source": [
    "#Username Input\n",
    "user_input = input(\"Enter desired Reddit Username to Archive:\")\n",
    "\n",
    "#Output Directory Input using Tkinter\n",
    "confirm_input = input(\"Choose Archive File Output Directory? (Y/N)\")\n",
    "\n",
    "#Select Output Directory if chosen\n",
    "if confirm_input.lower() == 'y':\n",
    "    root = Tk() \n",
    "    root.withdraw()\n",
    "    output_dir = filedialog.askdirectory()\n",
    "    root.destroy()\n",
    "    print(\"Will save archive file to: %s\" % output_dir)\n",
    "else:\n",
    "    print(\"No output directory selected - will save to current directory.\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 18, bypassing...\n",
      "https://www.reddit.com/over18/?dest=https%3A%2F%2Fold.reddit.com%2Fuser%2FThrowRAlostinspace0\n",
      "bypass working\n"
     ]
    }
   ],
   "source": [
    "user_url = 'https://old.reddit.com/user/'+user_input\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "form_data = {\"over18\": \"yes\"}\n",
    "response = requests.get(user_url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "title_check = soup.title.text.split(' ')[0]\n",
    "\n",
    "if title_check == \"overview\":\n",
    "    print(\"working\")\n",
    "else:\n",
    "    print(\"Over 18, bypassing...\")\n",
    "    age_url =soup.select_one('link[rel=\"canonical\"]')['href']\n",
    "    print(age_url)\n",
    "    new_response = requests.post(age_url, data=form_data, headers=headers)\n",
    "    soup = BeautifulSoup(new_response.content, 'html.parser')\n",
    "    title_check = soup.title.text.split(' ')[0]\n",
    "    if title_check == \"overview\":\n",
    "        print(\"bypass working\")\n",
    "    else:\n",
    "        print(\"bypass failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 18, bypassing...\n",
      "https://www.reddit.com/over18/?dest=https%3A%2F%2Fold.reddit.com%2Fuser%2FThrowRAlostinspace0\n",
      "bypass working\n"
     ]
    }
   ],
   "source": [
    "#Testing Scraping all pages of user profile and adding each to an array of soups\n",
    "user_url = 'https://old.reddit.com/user/'+user_input\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "form_data = {\"over18\": \"yes\"}\n",
    "soups = []\n",
    "response = requests.get(user_url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "title_check = soup.title.text.split(' ')[0]\n",
    "\n",
    "if title_check == \"overview\":\n",
    "    print(\"working\")\n",
    "    soups.append(soup) #Append first page\n",
    "else:\n",
    "    print(\"Over 18, bypassing...\")\n",
    "    age_url =soup.select_one('link[rel=\"canonical\"]')['href']\n",
    "    print(age_url)\n",
    "    new_response = requests.post(age_url, data=form_data, headers=headers)\n",
    "    soup = BeautifulSoup(new_response.content, 'html.parser')\n",
    "    title_check = soup.title.text.split(' ')[0]\n",
    "    if title_check == \"overview\":\n",
    "        print(\"bypass working\")\n",
    "        soups.append(soup) #Append first page\n",
    "    else:\n",
    "        print(\"bypass failed\")\n",
    "while True:\n",
    "    next_button = soup.find('span', class_='next-button')\n",
    "    if next_button:\n",
    "        href_link = next_button.find('a')['href']\n",
    "        response = requests.get(href_link, data=form_data, headers=headers)\n",
    "        soup2 = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_check = soup2.title.text.split(' ')[0]\n",
    "        if title_check == \"overview\":\n",
    "            print(\"working\")\n",
    "            soups.append(soup2) #Append first page\n",
    "            soup = soup2\n",
    "        else: #TODO BELOW IS NOT WORKING\n",
    "            print(\"Over 18, bypassing...\")\n",
    "            age_url =soup.select_one('link[rel=\"canonical\"]')['href']\n",
    "            print(age_url)\n",
    "            new_response = requests.post(age_url, data=form_data, headers=headers)\n",
    "            soup = BeautifulSoup(new_response.content, 'html.parser')\n",
    "            title_check = soup.title.text.split(' ')[0]\n",
    "            if title_check == \"overview\":\n",
    "                print(\"bypass working\")\n",
    "                soups.append(soup2) #Append first page\n",
    "                soup = soup2\n",
    "            else:\n",
    "                print(\"bypass failed\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: ThrowRAlostinspace0\n",
      "Comment Karma: 3\n",
      "Post Karma: 5\n",
      "Creation Date: 2023-06-17T17:03:50+00:00\n",
      "Posts Count: 2\n",
      "Comments Count: 16\n"
     ]
    }
   ],
   "source": [
    "username = soup.title.text.split(' ')[2]\n",
    "\n",
    "comment_karma_box = soup.find('span', {'class': 'comment-karma'})\n",
    "comment_karma = comment_karma_box.text if comment_karma_box is not None else ''\n",
    "comment_karma = int(comment_karma.replace(',', ''))\n",
    "post_karma = soup.find('span', {'class': 'karma'})\n",
    "post_karma = post_karma.text if post_karma is not None else ''\n",
    "post_karma = int(post_karma.replace(',', ''))\n",
    "\n",
    "user_creation_date = soup.find('span', {'class': 'age'})\n",
    "user_creation_date = user_creation_date.find('time')['datetime']\n",
    "\n",
    "num_posts = 0\n",
    "num_comments = 0\n",
    "for soup in soups:\n",
    "    for comment in soup.find_all('div', class_='comment'):\n",
    "        num_comments += 1\n",
    "    for post in soup.find_all('div', class_='link'):\n",
    "        num_posts += 1\n",
    "\n",
    "print(\"Username: \" + username)\n",
    "print(\"Comment Karma: %d\"  % comment_karma)\n",
    "print(\"Post Karma: %d\" % post_karma)\n",
    "print(\"Creation Date: \" + user_creation_date)\n",
    "print(\"Posts Count: %d\" % num_posts)\n",
    "print(\"Comments Count: %d\" % num_comments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'utc_date': '2023-07-26T17:32:29+00:00', 'score': '2 points', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsn4m/', 'text': 'I will make sure to try not to worry about that, even my friends told me my past is pretty normal\\n\\n'}, {'utc_date': '2023-07-26T17:31:23+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsgkr/', 'text': 'Well I do love him, and I wish for him to be my last and vice versa\\n\\n'}, {'utc_date': '2023-07-26T17:30:41+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsci8/', 'text': 'Guess I just sometimes forget those are normal experiences, especially if he asks me about then, I just start feeling like I did something bad, like I shouldnt have partners before him\\n\\n'}, {'utc_date': '2023-07-26T17:28:12+00:00', 'score': '2 points', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjrxok/', 'text': 'Yeah, I always thought those were just normal experiences, but I will definitely try to talk to a therapist as well\\n\\n'}, {'utc_date': '2023-07-26T17:26:03+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjrku5/', 'text': 'My friends told me that as well, guess Im just worried for no reason\\n\\n'}, {'utc_date': '2023-07-26T17:24:06+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjr9eu/', 'text': 'Well thats what Im thinking as well, past shouldnt matter, I know Im not a saint and neither he is, no one is tbh, and thats what im trying to tell him, whats important is how we feel about each other and how we treat each other\\n\\n'}, {'utc_date': '2023-07-26T17:19:36+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjqio0/', 'text': 'He always says my number is for sure higher cause I seem quite experienced to him, its just frustrating he doesnt belive what I tell him but still asks\\n\\n'}, {'utc_date': '2023-07-26T17:17:39+00:00', 'score': '1 point', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjq728/', 'text': 'Honestly I never thought I was until I met him, he is just way too traditional about stuff like that even though he had waaay more partners than I did\\n\\n'}, {'utc_date': '2023-07-26T17:15:53+00:00', 'score': '2 points', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjpwna/', 'text': 'Yeah, never thought it was until I started dating him, guess he kinda got to me\\n\\n'}, {'utc_date': '2023-07-26T17:15:02+00:00', 'score': '2 points', 'subreddit': 'SluttyConfessions', 'permalink': 'https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjprpc/', 'text': 'Tbh I was thinking about doing that just in case he mentions it again\\n\\n'}, {'utc_date': '2023-06-24T06:55:49+00:00', 'score': '1 point', 'subreddit': 'relationships', 'permalink': 'https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jpblt5y/', 'text': \"To be honest, I'm not anxious without reason, i won't go into the details but for him women and men are not the same, women shouldn't have the same experiences as men in his opinion, they can't have one night stands, sleep too quickly with someone otherwise they become low value, they are worthless and undeserving of love and marriage. That's why lately I've been thinking about breaking up him...\\n\\n\"}, {'utc_date': '2023-06-22T13:36:59+00:00', 'score': '0 points', 'subreddit': 'relationships', 'permalink': 'https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp3a46i/', 'text': \"I never thought it did until recently. I made mistakes and I learned from them, but I still feel like he would judge me and think less of me and I'm constantly trying to shake off these thoughts. Even my friend told me she had similar experiences, that those are normal and that her boyfriend never cared about her past, they just focused on the present.\\n\\n\"}, {'utc_date': '2023-06-21T23:01:22+00:00', 'score': '1 point', 'subreddit': 'relationship_advice', 'permalink': 'https://old.reddit.com/r/relationship_advice/comments/14fk0ny/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp0v81j/', 'text': \"No, not really. I thought it would be okay just to share the number of people I've been with, not every single detail but recently he mentioned we should just live together so I'm not sure anymore.\\n\\n\"}, {'utc_date': '2023-06-21T21:45:45+00:00', 'score': '0 points', 'subreddit': 'relationships', 'permalink': 'https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp0ky9z/', 'text': 'Nothing good to be honest. In fact, I just cry all the time and worry that he might break up with me because of this. I stopped smoking few months ago and now I started again just to \"calm down\"\\n\\n'}, {'utc_date': '2023-06-21T17:08:40+00:00', 'score': '1 point', 'subreddit': 'relationship_advice', 'permalink': 'https://old.reddit.com/r/relationship_advice/comments/14fa375/how_to_get_over_my_22f_past_now_that_i_have_found/jozf14t/', 'text': \"Hopefully I will get over this soon. What we have right now is really something special to me and I don't want my worries tu ruin this relationship.\\n\\n\"}, {'utc_date': '2023-06-21T15:24:31+00:00', 'score': '2 points', 'subreddit': 'relationship_advice', 'permalink': 'https://old.reddit.com/r/relationship_advice/comments/14fa375/how_to_get_over_my_22f_past_now_that_i_have_found/joyz2dl/', 'text': \"That's what I'm actually saying to myself, that decisions I made in the past perhaps brought me to him. I'm just sorry I couldn't give him something special, but gave it to someone who didn't even care in the end.\\n\\n\"}]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "comment_count = 0\n",
    "for soup in soups[:1]: \n",
    "    spans = []\n",
    "    score = \"\"\n",
    "    score_hidden = \"\"\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%S%z\"\n",
    "\n",
    "    for comment in soup.find_all('div', class_='comment'):\n",
    "        utc_date = comment.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        spans = comment.find('span', class_='score unvoted')\n",
    "        if spans is not None:\n",
    "            score = spans.text\n",
    "        else:\n",
    "            score = comment.find('span', class_='score-hidden').text\n",
    "        subreddit = comment.find('a', class_=\"subreddit\").text\n",
    "        permalink = comment.find('a', class_=\"bylink\")['href']\n",
    "        text = comment.find('div', class_='md-container').text\n",
    "        comment_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'text': text\n",
    "        }\n",
    "        comments.append(comment_data)\n",
    "        comment_count += 1\n",
    "\n",
    "    print(comments)\n",
    "    print(comment_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Counting Posts\n",
    "post_count = 0\n",
    "for soup in soups: \n",
    "    for post in soup.find_all('div', class_='link'):\n",
    "        post_count += 1\n",
    "    print(post_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dandex/programming/The_Reddit_Archiver/Reddit_Archiver/Temp_Files'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "post_count = 0\n",
    "\n",
    "for soup in soups: \n",
    "\n",
    "    utc_date = 0\n",
    "    post_type = \"\"\n",
    "    subreddit = \"\"\n",
    "    post_title = \"\"\n",
    "    file_path = \"\"\n",
    "    permalink = \"\"\n",
    "    score = 0\n",
    "    text = \"\"\n",
    "\n",
    "    #self post\n",
    "    for self_post in soup.find_all('div', class_='self'):\n",
    "        post_count += 1\n",
    "        utc_date = self_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"self\"\n",
    "        subreddit = self_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = self_post.find('a', class_=\"title\").text\n",
    "        score = self_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = self_post.find('a', class_=\"bylink\")['href']\n",
    "\n",
    "        if self_post.find('div', {'class': 'expando-button'}): \n",
    "\n",
    "            self_text_url = permalink\n",
    "\n",
    "            headers2 = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "            response2 = requests.get(self_text_url, headers=headers2)\n",
    "            soup2 = BeautifulSoup(response2.content, \"html.parser\")\n",
    "            post_content = soup2.find(\"div\", class_=\"entry\")\n",
    "            #md_element = post_content.find(\"div\", class_=\"md-container\")\n",
    "            #post_text = md_element.text\n",
    "            print(post_content)\n",
    "\n",
    "            #text = post_text\n",
    "            \n",
    "        else:\n",
    "            text = None\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'text': text\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "        \n",
    "    #crosspost\n",
    "    for cross_post in soup.find_all('div', {'class':'link', 'data-crosspost-root-title': True}):\n",
    "        post_count += 1\n",
    "        utc_date = cross_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"crosspost\"\n",
    "        subreddit = cross_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = cross_post.find('a', class_=\"title\").text\n",
    "        score = cross_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = cross_post.find('a', class_=\"bylink\")['href']\n",
    "        cross_post_link = cross_post.find('a', class_=\"title\")['href']\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            \"CrossPost Link\": cross_post_link\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "    #link\n",
    "    domains = ['old.reddit.com', 'i.redd.it', 'v.redd.it', 'i.imgur.com']\n",
    "    for link_post in soup.find_all(lambda tag: tag.has_attr('data-domain') and not any(domain in tag['data-domain'] for domain in domains )and 'self' not in tag.get('class', [])):\n",
    "        post_count += 1\n",
    "        utc_date = link_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"link\"\n",
    "        subreddit = link_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = link_post.find('a', class_=\"title\").text\n",
    "        score = link_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = link_post.find('a', class_=\"bylink\")['href']\n",
    "        \n",
    "        if link_post.find('div', {'class': 'expando-button'}): #If expando button present\n",
    "            #Download permalink\n",
    "            form_data = {\"over18\": \"yes\"}\n",
    "            response = requests.get(permalink, data=form_data, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            post_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            #Extract text\n",
    "            link = post_soup.find('a', class_=\"title\")['href']\n",
    "        else:\n",
    "            link = None\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'link': link\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "    #video\n",
    "    for video_post in soup.find_all('div', {'class':'link', \"data-domain\": \"v.redd.it\", \"data-kind\": \"video\"}):\n",
    "        post_count += 1\n",
    "        utc_date = video_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"video\"\n",
    "        subreddit = video_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = video_post.find('a', class_=\"title\").text\n",
    "        score = video_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = video_post.find('a', class_=\"bylink\")['href']\n",
    "        vid_link = video_post.find('a', class_=\"title\")['href']\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'outtmpl': f'{output_dir}/%(title)s.%(ext)s',\n",
    "            #'outtmpl': output_dir + ,\n",
    "            'merge_output_format': 'mp4',\n",
    "        }\n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([vid_link])\n",
    "        #Merge and Remove \n",
    "        for filename in os.listdir(output_dir):\n",
    "            if filename.endswith(\".mp4\") and \"merged\" not in filename:\n",
    "                video_path = os.path.join(output_dir, filename)\n",
    "                audio_filename_prefix = filename[:8]\n",
    "                \n",
    "                for file in os.listdir(output_dir):\n",
    "                    if file.startswith(audio_filename_prefix) and file.endswith(\".m4a\"):\n",
    "                        audio_path = os.path.join(output_dir, file)\n",
    "                        output_filename = os.path.splitext(filename)[0] + \"_merged.mp4\"\n",
    "                        output_path = os.path.join(output_dir, output_filename)\n",
    "                        video = VideoFileClip(video_path)\n",
    "                        audio = AudioFileClip(audio_path)\n",
    "                        video = video.set_audio(audio)\n",
    "                        video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "                        break\n",
    "                os.remove(video_path)\n",
    "                os.remove(audio_path)\n",
    "                vid_path = output_path\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'filepath': vid_path,\n",
    "            'text' : text\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "    #pictures \n",
    "\n",
    "    for pic_post in soup.find_all('div', {'class':'link', \"data-domain\": \"old.reddit.com\", \"data-is-gallery\": \"true\"}):\n",
    "        post_count += 1\n",
    "        utc_date = pic_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"pic-gallery\"\n",
    "        subreddit = pic_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = pic_post.find('a', class_=\"title\").text\n",
    "        score = pic_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = pic_post.find('a', class_=\"bylink\")['href']\n",
    "        gallery_link = pic_post.find('a', class_=\"title\")['href'] \n",
    "        filepaths = []\n",
    "        headers3 = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "        response3 = requests.get(gallery_link, headers=headers3)\n",
    "        soup3 = BeautifulSoup(response3.content, \"html.parser\")\n",
    "        presentation_div = soup3.find(\"div\", {\"role\": \"presentation\"})\n",
    "        a_elements = presentation_div.find_all(\"a\")\n",
    "        if a_elements:\n",
    "            for a_element in a_elements:\n",
    "                href_link = a_element.get(\"href\")\n",
    "                if href_link and href_link.startswith(\"https://preview\"):\n",
    "                    pic_filename = href_link.split(\"/\")[-1]  \n",
    "                    pic_filename = pic_filename.split(\".jpg\")[0] + \".jpg\"  \n",
    "                    pic_path = os.path.join(output_dir, pic_filename)\n",
    "                    urllib.request.urlretrieve(href_link, pic_path)\n",
    "                    filepaths.append(pic_path)\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'filepath': filepaths\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "\n",
    "    for pic_post in soup.find_all('div', {'class':'link', \"data-domain\": \"old.reddit.com\", \"data-is-gallery\": \"false\"}):\n",
    "        post_count += 1\n",
    "        utc_date = pic_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"pic-old\"\n",
    "        subreddit = pic_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = pic_post.find('a', class_=\"title\").text\n",
    "        score = pic_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = pic_post.find('a', class_=\"bylink\")['href']\n",
    "        pic_link = pic_post.find('a', class_=\"title\")['href']\n",
    "        pic_path = \"\"\n",
    "        pic_filename = pic_link.split(\"/\")[-1]  \n",
    "        pic_path = os.path.join(output_dir, pic_filename)\n",
    "        urllib.request.urlretrieve(pic_link, pic_path)\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'filepath': pic_path\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "    for pic_post in soup.find_all('div', {'class':'link', \"data-domain\": \"i.redd.it\"}):\n",
    "        post_count += 1\n",
    "        utc_date = pic_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"pic-i\"\n",
    "        subreddit = pic_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = pic_post.find('a', class_=\"title\").text\n",
    "        score = pic_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = pic_post.find('a', class_=\"bylink\")['href']\n",
    "        #pic_link = pic_post.find('a', class_=\"title\")['href']\n",
    "        pic_link = pic_post['data-url']\n",
    "        print(pic_link)\n",
    "        pic_path = \"\"\n",
    "        pic_filename = pic_link.split(\"/\")[-1]  \n",
    "        pic_path = os.path.join(output_dir, pic_filename)\n",
    " \n",
    "        urllib.request.urlretrieve(pic_link, pic_path)\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type,\n",
    "            'filepath': pic_path\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "\n",
    "    for pic_post in soup.find_all('div', {'class':'link', \"data-domain\": \"i.imgur.com\"}):\n",
    "        post_count += 1\n",
    "        utc_date = pic_post.find('time', class_=\"live-timestamp\")['datetime']\n",
    "        utc_date = datetime.datetime.strptime(utc_date, date_format)\n",
    "        utc_date = utc_date.isoformat()\n",
    "        post_type = \"pic-imgur\"\n",
    "        subreddit = pic_post.find('a', class_=\"subreddit\").text\n",
    "        post_title = pic_post.find('a', class_=\"title\").text\n",
    "        score = pic_post.find('div', {'class': 'score unvoted'}).text\n",
    "        permalink = pic_post.find('a', class_=\"bylink\")['href']\n",
    "        post_data = {\n",
    "            'utc_date': utc_date,\n",
    "            'score': score,\n",
    "            'subreddit': subreddit,\n",
    "            'permalink': permalink,\n",
    "            'title': post_title,\n",
    "            'type': post_type\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "\n",
    "    print(post_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    }
   ],
   "source": [
    "#Test if 25 Posts identified (Number of each page)\n",
    "if (post_count + comment_count) != (num_comments+num_posts):\n",
    "    print(\"Error\")\n",
    "else:\n",
    "    \n",
    "    print(\"working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_posts = len(posts)\n",
    "num_comments = len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = {\n",
    "    'user_info': {\n",
    "        'username': username,\n",
    "        'user_creation_date': user_creation_date,\n",
    "        'num_posts': num_posts,\n",
    "        'num_comments': num_comments,\n",
    "        'karma': {\n",
    "            'post_karma': post_karma,\n",
    "            'comment_karma': comment_karma\n",
    "        }\n",
    "    },\n",
    "    'posts': posts,\n",
    "    'comments': comments\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Temp_Files/user_data.json', 'w') as f:\n",
    "    json.dump(user_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"user_info\": {\n",
      "        \"username\": \"ThrowRAlostinspace0\",\n",
      "        \"user_creation_date\": \"2023-06-17T17:03:50+00:00\",\n",
      "        \"num_posts\": 2,\n",
      "        \"num_comments\": 16,\n",
      "        \"karma\": {\n",
      "            \"post_karma\": 5,\n",
      "            \"comment_karma\": 3\n",
      "        }\n",
      "    },\n",
      "    \"posts\": [\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-27T14:29:11+00:00\",\n",
      "            \"score\": \"14\",\n",
      "            \"subreddit\": \"r/AskRedditNSFW\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/AskRedditNSFW/comments/15b3dp1/am_i_23f_a_slut/\",\n",
      "            \"title\": \"Am I (23F) a slut?\",\n",
      "            \"type\": \"self\",\n",
      "            \"text\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T16:13:11+00:00\",\n",
      "            \"score\": \"6\",\n",
      "            \"subreddit\": \"r/SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/\",\n",
      "            \"title\": \"Am I (23F) a slut?\",\n",
      "            \"type\": \"self\",\n",
      "            \"text\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"comments\": [\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:32:29+00:00\",\n",
      "            \"score\": \"2 points\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsn4m/\",\n",
      "            \"text\": \"I will make sure to try not to worry about that, even my friends told me my past is pretty normal\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:31:23+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsgkr/\",\n",
      "            \"text\": \"Well I do love him, and I wish for him to be my last and vice versa\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:30:41+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjsci8/\",\n",
      "            \"text\": \"Guess I just sometimes forget those are normal experiences, especially if he asks me about then, I just start feeling like I did something bad, like I shouldnt have partners before him\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:28:12+00:00\",\n",
      "            \"score\": \"2 points\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjrxok/\",\n",
      "            \"text\": \"Yeah, I always thought those were just normal experiences, but I will definitely try to talk to a therapist as well\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:26:03+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjrku5/\",\n",
      "            \"text\": \"My friends told me that as well, guess Im just worried for no reason\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:24:06+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjr9eu/\",\n",
      "            \"text\": \"Well thats what Im thinking as well, past shouldnt matter, I know Im not a saint and neither he is, no one is tbh, and thats what im trying to tell him, whats important is how we feel about each other and how we treat each other\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:19:36+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjqio0/\",\n",
      "            \"text\": \"He always says my number is for sure higher cause I seem quite experienced to him, its just frustrating he doesnt belive what I tell him but still asks\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:17:39+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjq728/\",\n",
      "            \"text\": \"Honestly I never thought I was until I met him, he is just way too traditional about stuff like that even though he had waaay more partners than I did\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:15:53+00:00\",\n",
      "            \"score\": \"2 points\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjpwna/\",\n",
      "            \"text\": \"Yeah, never thought it was until I started dating him, guess he kinda got to me\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-07-26T17:15:02+00:00\",\n",
      "            \"score\": \"2 points\",\n",
      "            \"subreddit\": \"SluttyConfessions\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/SluttyConfessions/comments/15aa292/am_i_23f_a_slut/jtjprpc/\",\n",
      "            \"text\": \"Tbh I was thinking about doing that just in case he mentions it again\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-24T06:55:49+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"relationships\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jpblt5y/\",\n",
      "            \"text\": \"To be honest, I'm not anxious without reason, i won't go into the details but for him women and men are not the same, women shouldn't have the same experiences as men in his opinion, they can't have one night stands, sleep too quickly with someone otherwise they become low value, they are worthless and undeserving of love and marriage. That's why lately I've been thinking about breaking up him...\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-22T13:36:59+00:00\",\n",
      "            \"score\": \"0 points\",\n",
      "            \"subreddit\": \"relationships\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp3a46i/\",\n",
      "            \"text\": \"I never thought it did until recently. I made mistakes and I learned from them, but I still feel like he would judge me and think less of me and I'm constantly trying to shake off these thoughts. Even my friend told me she had similar experiences, that those are normal and that her boyfriend never cared about her past, they just focused on the present.\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-21T23:01:22+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"relationship_advice\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationship_advice/comments/14fk0ny/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp0v81j/\",\n",
      "            \"text\": \"No, not really. I thought it would be okay just to share the number of people I've been with, not every single detail but recently he mentioned we should just live together so I'm not sure anymore.\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-21T21:45:45+00:00\",\n",
      "            \"score\": \"0 points\",\n",
      "            \"subreddit\": \"relationships\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationships/comments/14fjui0/i_23f_constantly_feel_unworthy_of_my_boyfriends/jp0ky9z/\",\n",
      "            \"text\": \"Nothing good to be honest. In fact, I just cry all the time and worry that he might break up with me because of this. I stopped smoking few months ago and now I started again just to \\\"calm down\\\"\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-21T17:08:40+00:00\",\n",
      "            \"score\": \"1 point\",\n",
      "            \"subreddit\": \"relationship_advice\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationship_advice/comments/14fa375/how_to_get_over_my_22f_past_now_that_i_have_found/jozf14t/\",\n",
      "            \"text\": \"Hopefully I will get over this soon. What we have right now is really something special to me and I don't want my worries tu ruin this relationship.\\n\\n\"\n",
      "        },\n",
      "        {\n",
      "            \"utc_date\": \"2023-06-21T15:24:31+00:00\",\n",
      "            \"score\": \"2 points\",\n",
      "            \"subreddit\": \"relationship_advice\",\n",
      "            \"permalink\": \"https://old.reddit.com/r/relationship_advice/comments/14fa375/how_to_get_over_my_22f_past_now_that_i_have_found/joyz2dl/\",\n",
      "            \"text\": \"That's what I'm actually saying to myself, that decisions I made in the past perhaps brought me to him. I'm just sorry I couldn't give him something special, but gave it to someone who didn't even care in the end.\\n\\n\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('Temp_Files/user_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(json.dumps(data, indent=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-DO: PT1**\n",
    "* Successfully append comments, user info, and posts of first page to JSON in correct format\n",
    "* Save pictures/videos to directory\n",
    "* Present JSON and saved files in beginner format HTML webpage\n",
    "* Apply saving to all pages of reddit account\n",
    "* Add tests to ensure data is all saved (meets 25 posts per page, etc)\n",
    "* Create Readme on Github\n",
    "* Publish first time\n",
    "\n",
    "**TO-DO PT2**\n",
    "* Convert from notebook to script\n",
    "* Create GUI where you can choose if you want to save pics/videos, input user/output directory in GUI, etc\n",
    "* Apply ability to save pics/videos as choice\n",
    "* Create Pretty looking HTML archive page\n",
    "* Promote on Reddit\n",
    "* Release as second update \n",
    "* Add ability to keep link in comment\n",
    "\n",
    "**TO-DO PT3**\n",
    "* blank\n",
    "\n",
    "**Minor Additions**\n",
    "* Accounting for pinned posts\n",
    "* Profile pictures (snoovatar??)\n",
    "* Trophies\n",
    "* Add over 18 bypass for old.reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear Temp_Files\n",
    "for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
